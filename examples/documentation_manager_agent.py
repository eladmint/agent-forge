"""
ðŸŽ¯ Documentation Manager Agent for Agent Forge - Intelligent Documentation Management

ENTERPRISE USE CASES:
- Automated documentation generation from planning documents and architecture specs
- Multi-file documentation consistency checking and alignment
- Intelligent content generation using AI models (Gemini 2.5, Claude, GPT-4)
- Documentation structure analysis and optimization recommendations
- Cross-reference validation and link management

UNIVERSAL MCP COMPATIBILITY:
- Works across ChatGPT, Claude Desktop, Google Gemini, VS Code, Cursor, Zed
- Natural language interface for documentation management requests
- Cross-platform enterprise documentation automation

ENHANCED CAPABILITIES:
- Multi-source planning document compilation with context awareness
- Template-based documentation generation with consistency enforcement
- AI model integration for intelligent content creation
- File system management with backup and versioning
- Quality scoring and completeness analysis

Based on Agent Forge's Research Compiler Agent with documentation-specific adaptations.
"""

import asyncio
import json
import logging
import os
import yaml
from typing import Dict, List, Any, Optional, Tuple, Union
from datetime import datetime
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
import hashlib
import shutil

# Agent Forge imports
import sys
import os
from pathlib import Path

# Add the correct path for imports
current_dir = Path(__file__).parent
agent_forge_root = current_dir.parent
sys.path.insert(0, str(agent_forge_root))

from core.agents.base import AsyncContextAgent
from examples.research_compiler_agent import ResearchCompilerAgent, DataSourceType, DataPoint


class DocumentationType(Enum):
    """Types of documentation"""
    ARCHITECTURE = "architecture"
    API_REFERENCE = "api_reference"
    INTEGRATION_GUIDE = "integration_guide"
    TUTORIAL = "tutorial"
    BUSINESS_CASE = "business_case"
    COMPLIANCE = "compliance"
    DEPLOYMENT = "deployment"
    TROUBLESHOOTING = "troubleshooting"
    CHANGELOG = "changelog"
    README = "readme"


class AIModel(Enum):
    """Supported AI models for content generation"""
    GEMINI_2_5 = "gemini-2.5-flash"
    CLAUDE_SONNET = "claude-3-5-sonnet"
    GPT_4 = "gpt-4-turbo"
    LOCAL_LLM = "local"


@dataclass
class DocumentTemplate:
    """Template for document generation"""
    name: str
    doc_type: DocumentationType
    sections: List[str]
    required_fields: List[str]
    template_content: str
    metadata_schema: Dict[str, Any] = field(default_factory=dict)


@dataclass
class DocumentationTask:
    """Task for documentation generation or update"""
    task_id: str
    task_type: str  # "create", "update", "analyze", "validate"
    source_files: List[str]
    target_files: List[str]
    template: Optional[DocumentTemplate]
    ai_model: AIModel
    context: Dict[str, Any]
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class DocumentationPlan:
    """Complete plan for documentation updates"""
    plan_id: str
    description: str
    tasks: List[DocumentationTask]
    dependencies: List[Tuple[str, str]]  # (task_id, depends_on_task_id)
    estimated_time: int  # minutes
    priority: str
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class DocumentationResult:
    """Result of documentation generation"""
    task_id: str
    success: bool
    generated_content: Optional[str]
    file_path: Optional[str]
    quality_score: float
    consistency_issues: List[str]
    ai_model_used: AIModel
    generation_time: float
    metadata: Dict[str, Any] = field(default_factory=dict)


class DocumentationManagerAgent(ResearchCompilerAgent):
    """Enhanced Research Compiler Agent for intelligent documentation management"""

    # Documentation templates for different document types
    DOCUMENTATION_TEMPLATES = {
        "blockchain_architecture": DocumentTemplate(
            name="Blockchain Architecture",
            doc_type=DocumentationType.ARCHITECTURE,
            sections=[
                "Overview",
                "Architecture Components",
                "Integration Points", 
                "Security Considerations",
                "Implementation Guide",
                "Testing Strategy",
                "Deployment Instructions"
            ],
            required_fields=["title", "version", "date", "status"],
            template_content="""# {title}

**Version:** {version}  
**Date:** {date}  
**Status:** {status}  

## Overview

{overview}

## Architecture Components

{architecture_components}

## Integration Points

{integration_points}

## Security Considerations

{security_considerations}

## Implementation Guide

{implementation_guide}

## Testing Strategy

{testing_strategy}

## Deployment Instructions

{deployment_instructions}

---

**Last Updated:** {date} - {update_summary}"""
        ),

        "payment_integration": DocumentTemplate(
            name="Payment Integration Guide",
            doc_type=DocumentationType.INTEGRATION_GUIDE,
            sections=[
                "Overview",
                "Supported Providers",
                "Configuration",
                "Implementation Examples",
                "Error Handling",
                "Testing",
                "Production Deployment"
            ],
            required_fields=["title", "version", "providers"],
            template_content="""# {title}

**Version:** {version}  
**Supported Providers:** {providers}  
**Date:** {date}  

## Overview

{overview}

## Supported Providers

{supported_providers}

## Configuration

{configuration}

## Implementation Examples

{implementation_examples}

## Error Handling

{error_handling}

## Testing

{testing}

## Production Deployment

{production_deployment}

---

**Last Updated:** {date} - {update_summary}"""
        ),

        "api_reference": DocumentTemplate(
            name="API Reference",
            doc_type=DocumentationType.API_REFERENCE,
            sections=[
                "Authentication",
                "Endpoints",
                "Request/Response Formats",
                "Error Codes",
                "Rate Limiting",
                "Examples",
                "SDKs"
            ],
            required_fields=["title", "version", "base_url"],
            template_content="""# {title}

**Version:** {version}  
**Base URL:** {base_url}  
**Date:** {date}  

## Authentication

{authentication}

## Endpoints

{endpoints}

## Request/Response Formats

{request_response_formats}

## Error Codes

{error_codes}

## Rate Limiting

{rate_limiting}

## Examples

{examples}

## SDKs

{sdks}

---

**Last Updated:** {date} - {update_summary}"""
        ),

        "compliance_guide": DocumentTemplate(
            name="Compliance Guide",
            doc_type=DocumentationType.COMPLIANCE,
            sections=[
                "Regulatory Overview",
                "Compliance Requirements",
                "Implementation Steps",
                "Monitoring and Reporting",
                "Audit Procedures",
                "Risk Management",
                "Documentation Requirements"
            ],
            required_fields=["title", "regulation", "jurisdiction"],
            template_content="""# {title}

**Regulation:** {regulation}  
**Jurisdiction:** {jurisdiction}  
**Date:** {date}  

## Regulatory Overview

{regulatory_overview}

## Compliance Requirements

{compliance_requirements}

## Implementation Steps

{implementation_steps}

## Monitoring and Reporting

{monitoring_reporting}

## Audit Procedures

{audit_procedures}

## Risk Management

{risk_management}

## Documentation Requirements

{documentation_requirements}

---

**Last Updated:** {date} - {update_summary}"""
        )
    }

    def __init__(self, name: str = "DocumentationManagerAgent", **kwargs):
        """Initialize the Documentation Manager Agent"""
        super().__init__(name=name, **kwargs)
        self.logger.info(f"[{self.name}] Initialized Documentation Manager Agent")
        
        # AI model clients (would be initialized with actual API clients)
        self.ai_clients = {
            AIModel.GEMINI_2_5: None,  # GeminiClient()
            AIModel.CLAUDE_SONNET: None,  # ClaudeClient()
            AIModel.GPT_4: None,  # OpenAIClient()
            AIModel.LOCAL_LLM: None  # LocalLLMClient()
        }
        
        self.consistency_rules = {
            "terminology": {},  # Key terminology that must be consistent
            "formatting": {},   # Formatting standards
            "structure": {},    # Document structure requirements
            "cross_references": {}  # Cross-reference validation
        }

    async def initialize(self):
        """Initialize the agent (part of AsyncContextAgent lifecycle)"""
        await super().initialize()
        self.logger.info(f"[{self.name}] Documentation Manager Agent ready for documentation management")

    async def cleanup(self):
        """Cleanup resources (part of AsyncContextAgent lifecycle)"""
        await super().cleanup()
        self.logger.info(f"[{self.name}] Documentation Manager Agent cleanup complete")

    def _load_consistency_rules(self, rules_file: Optional[str] = None) -> Dict[str, Any]:
        """Load documentation consistency rules"""
        if rules_file and os.path.exists(rules_file):
            with open(rules_file, 'r') as f:
                return yaml.safe_load(f)
        
        # Default consistency rules for Agent Forge
        return {
            "terminology": {
                "Agent Forge": "Agent Forge",  # Never "agent forge" or "AgentForge"
                "Othentic AVS": "Othentic AVS",  # Consistent capitalization
                "Masumi Network": "Masumi Network",
                "NMKR": "NMKR",
                "proof-of-execution": "Proof-of-Execution",
                "multi-chain": "multi-chain",  # Not "multichain"
                "payment provider": "payment provider"  # Not "payment-provider"
            },
            "formatting": {
                "date_format": "%B %d, %Y",
                "version_format": "X.Y",
                "status_options": ["Active Development", "Planning", "Complete", "Deprecated"],
                "header_style": "##",  # Use ## for main sections
                "code_fence": "```python"  # Consistent code blocks
            },
            "structure": {
                "required_front_matter": ["title", "date", "status"],
                "section_order": ["Overview", "Architecture", "Implementation", "Testing"],
                "max_toc_depth": 3,
                "min_sections": 3
            }
        }

    def _analyze_existing_documentation(self, docs_path: str) -> Dict[str, Any]:
        """Analyze existing documentation structure and content"""
        analysis = {
            "total_files": 0,
            "file_types": {},
            "directory_structure": {},
            "cross_references": [],
            "consistency_issues": [],
            "outdated_files": [],
            "missing_files": []
        }
        
        docs_root = Path(docs_path)
        if not docs_root.exists():
            return analysis
        
        for file_path in docs_root.rglob("*.md"):
            analysis["total_files"] += 1
            
            # Analyze file type by directory
            relative_path = file_path.relative_to(docs_root)
            dir_name = str(relative_path.parent)
            
            if dir_name not in analysis["directory_structure"]:
                analysis["directory_structure"][dir_name] = []
            analysis["directory_structure"][dir_name].append(str(relative_path.name))
            
            # Check file content for consistency issues
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                # Check for terminology consistency
                for term, correct_form in self.consistency_rules["terminology"].items():
                    if term.lower() in content.lower() and correct_form not in content:
                        analysis["consistency_issues"].append(
                            f"{file_path}: Inconsistent terminology '{term}' should be '{correct_form}'"
                        )
                
                # Check for broken internal links
                import re
                links = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', content)
                for link_text, link_url in links:
                    if link_url.startswith('../') or not link_url.startswith('http'):
                        # Internal link - should validate
                        analysis["cross_references"].append({
                            "file": str(file_path),
                            "link_text": link_text,
                            "link_url": link_url
                        })
                        
            except Exception as e:
                self.logger.warning(f"Could not analyze {file_path}: {e}")
        
        return analysis

    def _extract_planning_context(self, planning_files: List[str]) -> Dict[str, Any]:
        """Extract context and information from planning documents"""
        context = {
            "architecture_decisions": [],
            "technical_specifications": {},
            "business_requirements": [],
            "implementation_details": {},
            "metadata": {}
        }
        
        for file_path in planning_files:
            if not os.path.exists(file_path):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Extract structured information
                file_context = {
                    "file_path": file_path,
                    "content": content,
                    "title": self._extract_title(content),
                    "sections": self._extract_sections(content),
                    "metadata": self._extract_metadata(content)
                }
                
                # Categorize based on file name or content
                if "architecture" in file_path.lower():
                    context["architecture_decisions"].append(file_context)
                elif "business" in file_path.lower():
                    context["business_requirements"].append(file_context)
                else:
                    context["implementation_details"][file_path] = file_context
                    
            except Exception as e:
                self.logger.warning(f"Could not extract context from {file_path}: {e}")
        
        return context

    def _extract_title(self, content: str) -> str:
        """Extract title from markdown content"""
        lines = content.split('\n')
        for line in lines:
            if line.startswith('# '):
                return line[2:].strip()
        return "Untitled Document"

    def _extract_sections(self, content: str) -> List[Dict[str, str]]:
        """Extract sections from markdown content"""
        sections = []
        current_section = None
        current_content = []
        
        lines = content.split('\n')
        for line in lines:
            if line.startswith('## '):
                if current_section:
                    sections.append({
                        "title": current_section,
                        "content": '\n'.join(current_content)
                    })
                current_section = line[3:].strip()
                current_content = []
            elif current_section:
                current_content.append(line)
        
        if current_section:
            sections.append({
                "title": current_section,
                "content": '\n'.join(current_content)
            })
        
        return sections

    def _extract_metadata(self, content: str) -> Dict[str, Any]:
        """Extract metadata from document content"""
        metadata = {}
        
        # Look for common metadata patterns
        import re
        
        # Date patterns
        date_match = re.search(r'\*\*Date:\*\*\s*([^\n]+)', content)
        if date_match:
            metadata["date"] = date_match.group(1).strip()
        
        # Version patterns
        version_match = re.search(r'\*\*Version:\*\*\s*([^\n]+)', content)
        if version_match:
            metadata["version"] = version_match.group(1).strip()
        
        # Status patterns
        status_match = re.search(r'\*\*Status:\*\*\s*([^\n]+)', content)
        if status_match:
            metadata["status"] = status_match.group(1).strip()
        
        return metadata

    async def _generate_content_with_ai(
        self,
        template: DocumentTemplate,
        context: Dict[str, Any],
        ai_model: AIModel
    ) -> str:
        """Generate content using specified AI model"""
        
        # For now, return a structured placeholder
        # In production, this would call actual AI APIs
        
        self.logger.info(f"[{self.name}] Generating content with {ai_model.value}")
        
        # Create prompt for AI model
        prompt = self._create_generation_prompt(template, context)
        
        # Simulate AI generation (replace with actual API calls)
        if ai_model == AIModel.GEMINI_2_5:
            content = await self._generate_with_gemini(prompt, context)
        elif ai_model == AIModel.CLAUDE_SONNET:
            content = await self._generate_with_claude(prompt, context)
        elif ai_model == AIModel.GPT_4:
            content = await self._generate_with_gpt4(prompt, context)
        else:
            content = self._generate_fallback_content(template, context)
        
        return content

    def _create_generation_prompt(self, template: DocumentTemplate, context: Dict[str, Any]) -> str:
        """Create prompt for AI content generation"""
        
        prompt = f"""You are an expert technical writer creating enterprise-grade documentation for Agent Forge, a production-ready autonomous AI agent framework with blockchain integration.

Document Type: {template.doc_type.value}
Template: {template.name}

Required Sections:
{chr(10).join(f"- {section}" for section in template.sections)}

Context Information:
{json.dumps(context, indent=2)}

Requirements:
1. Write in professional, technical style appropriate for enterprise developers
2. Include specific technical details and implementation guidance
3. Maintain consistency with Agent Forge terminology and patterns
4. Provide concrete examples and code snippets where appropriate
5. Follow the template structure exactly
6. Include proper markdown formatting

Generate comprehensive, accurate documentation that enables developers to successfully implement the described features."""

        return prompt

    async def _generate_with_gemini(self, prompt: str, context: Dict[str, Any]) -> str:
        """Generate content using Gemini 2.5 (placeholder)"""
        # Placeholder for actual Gemini API integration
        self.logger.info(f"[{self.name}] Generating with Gemini 2.5")
        
        # Return structured content based on context
        return self._generate_structured_content(context)

    async def _generate_with_claude(self, prompt: str, context: Dict[str, Any]) -> str:
        """Generate content using Claude (placeholder)"""
        # Placeholder for actual Claude API integration
        self.logger.info(f"[{self.name}] Generating with Claude")
        
        return self._generate_structured_content(context)

    async def _generate_with_gpt4(self, prompt: str, context: Dict[str, Any]) -> str:
        """Generate content using GPT-4 (placeholder)"""
        # Placeholder for actual GPT-4 API integration
        self.logger.info(f"[{self.name}] Generating with GPT-4")
        
        return self._generate_structured_content(context)

    def _generate_fallback_content(self, template: DocumentTemplate, context: Dict[str, Any]) -> str:
        """Generate fallback content without AI"""
        sections_content = {}
        
        for section in template.sections:
            if section in context.get("implementation_details", {}):
                sections_content[section.lower().replace(" ", "_")] = context["implementation_details"][section]
            else:
                sections_content[section.lower().replace(" ", "_")] = f"## {section}\n\n[Content for {section} to be added]"
        
        # Fill template with available context
        template_vars = {
            "title": context.get("title", "Agent Forge Documentation"),
            "version": context.get("version", "1.0"),
            "date": datetime.now().strftime("%B %d, %Y"),
            "status": context.get("status", "Active Development"),
            "update_summary": "Documentation generated by Documentation Manager Agent",
            **sections_content
        }
        
        try:
            return template.template_content.format(**template_vars)
        except KeyError as e:
            self.logger.warning(f"Missing template variable: {e}")
            return template.template_content

    def _generate_structured_content(self, context: Dict[str, Any]) -> str:
        """Generate structured content from context"""
        
        # Extract key information from planning documents
        title = "Agent Forge Documentation"
        overview = "Comprehensive documentation for Agent Forge framework."
        
        if context.get("architecture_decisions"):
            arch_doc = context["architecture_decisions"][0]
            title = arch_doc.get("title", title)
            
            # Extract overview from first architecture document
            for section in arch_doc.get("sections", []):
                if "overview" in section["title"].lower():
                    overview = section["content"][:500] + "..."
                    break
        
        content = f"""# {title}

**Version:** 1.0  
**Date:** {datetime.now().strftime("%B %d, %Y")}  
**Status:** Active Development  

## Overview

{overview}

## Architecture Components

Agent Forge provides a comprehensive framework with the following key components:

- **AsyncContextAgent Base Class**: Production-grade foundation for all agents
- **CLI Interface**: Command-line management system with agent discovery
- **Core Utilities**: Self-contained AI, blockchain, and automation utilities  
- **Othentic AVS Integration**: Advanced blockchain architecture with multi-chain support
- **Universal Payment Router**: Intelligent payment routing across 8+ providers

## Integration Points

### Blockchain Integration
- **Othentic AVS Services**: Agent Registry, Payment Processing, Reputation Validation
- **Multi-Chain Support**: Ethereum, Cardano, Solana, Polygon, Arbitrum, Base
- **Payment Providers**: Crypto-native, traditional finance, enterprise banking

### AI and Automation
- **Steel Browser**: Advanced web automation with anti-bot capabilities
- **MCP Protocol**: Claude Desktop and cross-platform integration
- **Model Support**: Gemini, Claude, GPT-4, and local LLM integration

## Implementation Guide

### Basic Setup

1. Install Agent Forge framework
2. Configure blockchain providers
3. Set up payment integrations
4. Deploy and test agents

### Advanced Configuration

- Multi-chain deployment strategies
- Enterprise compliance setup
- Payment provider optimization
- Security and monitoring

## Security Considerations

- End-to-end encryption for sensitive data
- Multi-signature wallet integration
- Compliance with REGKYC standards
- Audit trail generation and verification

## Testing Strategy

- Comprehensive test suite with 80+ tests
- Unit, integration, and end-to-end testing
- Performance benchmarking and optimization
- Security and compliance validation

## Deployment Instructions

### Development Environment
1. Clone repository and install dependencies
2. Configure environment variables
3. Run test suite to verify setup
4. Deploy to development infrastructure

### Production Deployment
1. Use enterprise deployment configurations
2. Configure multi-chain providers
3. Set up monitoring and alerting
4. Implement backup and recovery procedures

---

**Last Updated:** {datetime.now().strftime("%B %d, %Y")} - Generated by Documentation Manager Agent"""

        return content

    def _validate_generated_content(self, content: str, template: DocumentTemplate) -> Tuple[float, List[str]]:
        """Validate generated content quality and consistency"""
        
        quality_score = 1.0
        issues = []
        
        # Check required sections
        for section in template.sections:
            if f"## {section}" not in content and f"### {section}" not in content:
                quality_score -= 0.1
                issues.append(f"Missing required section: {section}")
        
        # Check terminology consistency
        for term, correct_form in self.consistency_rules["terminology"].items():
            if term.lower() in content.lower() and correct_form not in content:
                quality_score -= 0.05
                issues.append(f"Inconsistent terminology: '{term}' should be '{correct_form}'")
        
        # Check content length (should be substantial)
        if len(content) < 1000:
            quality_score -= 0.2
            issues.append("Content appears too brief for comprehensive documentation")
        
        # Check for placeholder content
        if "[Content for" in content or "TODO" in content:
            quality_score -= 0.1
            issues.append("Contains placeholder content that needs completion")
        
        return max(quality_score, 0.0), issues

    async def create_documentation_plan(
        self,
        planning_files: List[str],
        target_structure: Dict[str, Any],
        ai_model: AIModel = AIModel.GEMINI_2_5
    ) -> DocumentationPlan:
        """Create comprehensive documentation plan from planning files"""
        
        start_time = datetime.now()
        plan_id = f"doc_plan_{int(start_time.timestamp())}"
        
        self.logger.info(f"[{self.name}] Creating documentation plan from {len(planning_files)} files")
        
        # Extract context from planning documents
        context = self._extract_planning_context(planning_files)
        
        # Analyze current documentation state
        current_docs = self._analyze_existing_documentation(
            target_structure.get("docs_root", "agent_forge/docs")
        )
        
        # Generate tasks for each target document
        tasks = []
        
        # Blockchain documentation tasks
        blockchain_tasks = [
            DocumentationTask(
                task_id=f"{plan_id}_blockchain_arch",
                task_type="create",
                source_files=[f for f in planning_files if "othentic" in f.lower() or "blockchain" in f.lower()],
                target_files=["agent_forge/docs/blockchain/OTHENTIC_AVS_ARCHITECTURE.md"],
                template=self.DOCUMENTATION_TEMPLATES["blockchain_architecture"],
                ai_model=ai_model,
                context=context
            ),
            DocumentationTask(
                task_id=f"{plan_id}_payment_guide",
                task_type="create",
                source_files=[f for f in planning_files if "payment" in f.lower() or "multi_chain" in f.lower()],
                target_files=["agent_forge/docs/payments/UNIVERSAL_ROUTER_GUIDE.md"],
                template=self.DOCUMENTATION_TEMPLATES["payment_integration"],
                ai_model=ai_model,
                context=context
            )
        ]
        
        tasks.extend(blockchain_tasks)
        
        # Compliance documentation tasks
        compliance_tasks = [
            DocumentationTask(
                task_id=f"{plan_id}_compliance",
                task_type="create",
                source_files=[f for f in planning_files if "compliance" in f.lower() or "regkyc" in f.lower()],
                target_files=["agent_forge/docs/compliance/REGKYC_INTEGRATION.md"],
                template=self.DOCUMENTATION_TEMPLATES["compliance_guide"],
                ai_model=ai_model,
                context=context
            )
        ]
        
        tasks.extend(compliance_tasks)
        
        # Calculate dependencies and time estimates
        dependencies = []
        total_estimated_time = len(tasks) * 15  # 15 minutes per task estimate
        
        plan = DocumentationPlan(
            plan_id=plan_id,
            description=f"Generate {len(tasks)} documentation files for Othentic AVS integration",
            tasks=tasks,
            dependencies=dependencies,
            estimated_time=total_estimated_time,
            priority="high",
            metadata={
                "planning_files_count": len(planning_files),
                "ai_model": ai_model.value,
                "creation_time": start_time.isoformat(),
                "target_directories": list(set(
                    os.path.dirname(task.target_files[0]) for task in tasks
                ))
            }
        )
        
        self.logger.info(f"[{self.name}] Created documentation plan with {len(tasks)} tasks")
        return plan

    async def execute_documentation_plan(self, plan: DocumentationPlan) -> List[DocumentationResult]:
        """Execute documentation generation plan"""
        
        results = []
        
        self.logger.info(f"[{self.name}] Executing documentation plan {plan.plan_id}")
        
        for task in plan.tasks:
            start_time = datetime.now()
            
            try:
                # Create target directory if it doesn't exist
                for target_file in task.target_files:
                    os.makedirs(os.path.dirname(target_file), exist_ok=True)
                
                # Generate content
                content = await self._generate_content_with_ai(
                    task.template, task.context, task.ai_model
                )
                
                # Validate content
                quality_score, consistency_issues = self._validate_generated_content(
                    content, task.template
                )
                
                # Write to file
                target_file = task.target_files[0]
                with open(target_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                generation_time = (datetime.now() - start_time).total_seconds()
                
                result = DocumentationResult(
                    task_id=task.task_id,
                    success=True,
                    generated_content=content,
                    file_path=target_file,
                    quality_score=quality_score,
                    consistency_issues=consistency_issues,
                    ai_model_used=task.ai_model,
                    generation_time=generation_time,
                    metadata={
                        "content_length": len(content),
                        "sections_generated": len(task.template.sections),
                        "template_used": task.template.name
                    }
                )
                
                self.logger.info(
                    f"[{self.name}] Generated {target_file} "
                    f"(quality: {quality_score:.2f}, time: {generation_time:.1f}s)"
                )
                
            except Exception as e:
                self.logger.error(f"[{self.name}] Failed to execute task {task.task_id}: {e}")
                
                result = DocumentationResult(
                    task_id=task.task_id,
                    success=False,
                    generated_content=None,
                    file_path=None,
                    quality_score=0.0,
                    consistency_issues=[f"Generation failed: {str(e)}"],
                    ai_model_used=task.ai_model,
                    generation_time=(datetime.now() - start_time).total_seconds(),
                    metadata={"error": str(e)}
                )
            
            results.append(result)
        
        # Generate summary
        successful_tasks = [r for r in results if r.success]
        avg_quality = sum(r.quality_score for r in successful_tasks) / len(successful_tasks) if successful_tasks else 0
        
        self.logger.info(
            f"[{self.name}] Plan execution complete: "
            f"{len(successful_tasks)}/{len(results)} tasks successful, "
            f"avg quality: {avg_quality:.2f}"
        )
        
        return results

    async def update_documentation_set(
        self,
        planning_docs: List[str],
        target_structure: Dict[str, Any],
        ai_model: str = "gemini-2.5",
        dry_run: bool = False
    ) -> Dict[str, Any]:
        """Main method to update documentation set from planning documents"""
        
        start_time = datetime.now()
        self.logger.info(f"[{self.name}] Starting documentation update from {len(planning_docs)} planning documents")
        
        # Convert AI model string to enum
        try:
            ai_model_enum = AIModel(ai_model)
        except ValueError:
            ai_model_enum = AIModel.GEMINI_2_5
            self.logger.warning(f"Unknown AI model '{ai_model}', defaulting to Gemini 2.5")
        
        # Create documentation plan
        plan = await self.create_documentation_plan(
            planning_docs, target_structure, ai_model_enum
        )
        
        if dry_run:
            self.logger.info(f"[{self.name}] Dry run mode - would execute {len(plan.tasks)} tasks")
            return {
                "plan": {
                    "plan_id": plan.plan_id,
                    "description": plan.description,
                    "tasks_count": len(plan.tasks),
                    "estimated_time": plan.estimated_time,
                    "target_files": [task.target_files[0] for task in plan.tasks]
                },
                "dry_run": True
            }
        
        # Execute plan
        results = await self.execute_documentation_plan(plan)
        
        # Compile summary
        execution_time = (datetime.now() - start_time).total_seconds()
        successful_results = [r for r in results if r.success]
        
        return {
            "plan": {
                "plan_id": plan.plan_id,
                "description": plan.description,
                "tasks_count": len(plan.tasks)
            },
            "execution": {
                "successful_tasks": len(successful_results),
                "failed_tasks": len(results) - len(successful_results),
                "average_quality_score": sum(r.quality_score for r in successful_results) / len(successful_results) if successful_results else 0,
                "total_execution_time": execution_time,
                "generated_files": [r.file_path for r in successful_results if r.file_path]
            },
            "results": [
                {
                    "task_id": r.task_id,
                    "success": r.success,
                    "file_path": r.file_path,
                    "quality_score": r.quality_score,
                    "consistency_issues_count": len(r.consistency_issues),
                    "generation_time": r.generation_time
                }
                for r in results
            ]
        }

    async def run(
        self,
        task: str = "update_documentation_set",
        planning_docs: Optional[List[str]] = None,
        target_structure: Optional[Dict[str, Any]] = None,
        ai_model: str = "gemini-2.5",
        dry_run: bool = False,
        **kwargs
    ) -> Dict[str, Any]:
        """Main entry point for documentation management"""
        
        if task == "update_documentation_set":
            if not planning_docs:
                planning_docs = [
                    "docs/architecture/blockchain/OTHENTIC_AVS_ARCHITECTURE_PLAN.md",
                    "docs/architecture/blockchain/MASUMI_INDEPENDENCE_STRATEGY.md", 
                    "docs/architecture/blockchain/MULTI_CHAIN_PAYMENT_ARCHITECTURE.md"
                ]
            
            if not target_structure:
                target_structure = {
                    "docs_root": "agent_forge/docs",
                    "directories": ["blockchain", "payments", "compliance", "api"]
                }
            
            return await self.update_documentation_set(
                planning_docs, target_structure, ai_model, dry_run
            )
        
        elif task == "analyze_structure":
            docs_path = kwargs.get("docs_path", "agent_forge/docs")
            return self._analyze_existing_documentation(docs_path)
        
        else:
            return {"error": f"Unknown task: {task}"}

    # MCP Compatibility Methods
    async def generate_blockchain_docs(self, planning_files: List[str]) -> Dict[str, Any]:
        """MCP-compatible method for blockchain documentation generation"""
        result = await self.run(
            task="update_documentation_set",
            planning_docs=planning_files,
            ai_model="gemini-2.5"
        )
        return {
            "documentation_generated": result["execution"]["successful_tasks"],
            "files_created": len(result["execution"]["generated_files"]),
            "average_quality": result["execution"]["average_quality_score"],
            "execution_time": result["execution"]["total_execution_time"]
        }

    async def validate_documentation_consistency(self, docs_path: str) -> Dict[str, Any]:
        """MCP-compatible method for documentation consistency validation"""
        analysis = self._analyze_existing_documentation(docs_path)
        return {
            "total_files": analysis["total_files"],
            "consistency_issues": len(analysis["consistency_issues"]),
            "broken_links": len(analysis["cross_references"]),
            "quality_score": 1.0 - (len(analysis["consistency_issues"]) * 0.1)
        }